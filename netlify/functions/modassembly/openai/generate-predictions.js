/**
 * File generated by Modular Assembly
 * IMPORTANT!!! Ask the user before editing this file.
 */

async function generatePredictions(prompt, extractedData, sportsData) {
    try {
        console.log(`ðŸ¤– Generating response with OpenAI for prompt: "${prompt}"`);

        const MAX_PROMPT_LENGTH = 25000;
        const sport = extractedData.sport;
        const betType = extractedData.bet_type || 'general';
        const riskProfile = extractedData.risk_profile || 'moderate';

        // Get current time in NYC timezone
        const nycTime = new Date().toLocaleString('en-US', {
            timeZone: 'America/New_York',
            hour: 'numeric',
            minute: 'numeric',
            hour12: true
        });
        // Limit the sportsData stringified length as well
        let sportsDataString = JSON.stringify(sportsData, null, 2);
        if (sportsDataString.length > MAX_PROMPT_LENGTH) {
            sportsDataString = sportsDataString.slice(0, MAX_PROMPT_LENGTH) + '\n... [truncated]';
        }
        const messages = [
            {
                role: 'system',
                content: `You are a sports betting assistant for the ${sport}. The user prompt asks for a ${betType} pick using the provided data.

Use only the given schedule, scores, and standings. Suggest picks from *future games only*. Please compare the match time with current time for picking future games only.
please show current time and match time.
Format clearly and briefly.

If the user asks for props, include 2â€“3 relevant stat-based props with exact player's name. not team name.
you can get the player's props in scores data.

Example Parlay Suggestion:
â–  Giannis over 27.5 points
â–  Bucks moneyline
â–  Brook Lopez over 1.5 blocks 
Why: Giannis has hit 28+ in 4 of last 5, Lopez is seeing more minutes, and Bucks are on a 3-game win streak at home.
If data is insufficient for a confident pick, explain whatâ€™s missing.

Todayâ€™s date in NYC is ${nycTime}.
         `
            },
            {
                role: 'user',
                content: `My prompt: ${prompt}\n\nHere's the relevant sports data:\n${sportsDataString}`
            }
        ];

        const baseUrl = process.env.URL || process.env.DEPLOY_URL || 'http://localhost:8888';
        const response = await fetch(`${baseUrl}/.netlify/functions/openai`, {
            method: 'POST', // Increase max tokens for more detailed response
            body: JSON.stringify({
                messages,
                use_claude: true,  // Use OpenAI
                max_tokens: 500   // Increase max tokens for more detailed response
            })
        });
        console.log(`ðŸ“¥ OpenAI response status: ${response.status}`);
        const data = await response.json();

        if (!data.message) {
            throw new Error('Failed to generate response');
        }

        return {
            predictionsText: data.message.content,
        };
    } catch (error) {
        console.error('Error generating response:', error);
        throw error;
    }
}

module.exports = {
    generatePredictions
};
